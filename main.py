import streamlit as st
import requests
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import re

API_KEY = 'ì—¬ê¸°ì—_ë„ˆ_API_í‚¤_ë„£ì–´ë¼'

# ëª¨ë¸ ì¤€ë¹„
@st.cache_resource
def load_model():
    tokenizer = AutoTokenizer.from_pretrained("beomi/KcELECTRA-base")
    model = AutoModelForSequenceClassification.from_pretrained("beomi/KcELECTRA-base")
    return tokenizer, model

tokenizer, model = load_model()

def classify_comment(comment):
    inputs = tokenizer(comment, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1)
        label = torch.argmax(probs).item()
    return label  # 0: ë¶€ì •, 1: ì¤‘ë¦½, 2: ê¸ì • (ì´ ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)

def extract_video_id(url):
    match = re.search(r"(?:v=|youtu\.be/)([a-zA-Z0-9_-]{11})", url)
    return match.group(1) if match else None

def get_comments(video_id):
    comments = []
    next_page_token = ''

    while True:
        url = (
            f"https://www.googleapis.com/youtube/v3/commentThreads"
            f"?part=snippet&videoId={video_id}&key={API_KEY}&maxResults=100&pageToken={next_page_token}"
        )
        res = requests.get(url)
        data = res.json()

        for item in data.get("items", []):
            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']
            comments.append(comment)

        next_page_token = data.get("nextPageToken")
        if not next_page_token:
            break

    return comments

# Streamlit UI
st.title("ğŸ§  YouTube ì•…í”Œ ê°ì„±ë¶„ì„ê¸°")
video_url = st.text_input("YouTube ì˜ìƒ URLì„ ì…ë ¥í•˜ì„¸ìš”")

if st.button("ë¶„ì„ ì‹œì‘"):
    with st.spinner("ëŒ“ê¸€ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        video_id = extract_video_id(video_url)
        if not video_id:
            st.error("ì˜¬ë°”ë¥¸ URLì´ ì•„ë‹˜")
        else:
            try:
                comments = get_comments(video_id)
                st.write(f"ì „ì²´ ëŒ“ê¸€ ìˆ˜: {len(comments)}ê°œ")

                hate_comments = []
                for c in comments:
                    label = classify_comment(c)
                    if label == 0:  # ë¶€ì •
                        hate_comments.append(c)

                st.success(f"ì•…í”Œë¡œ ë¶„ë¥˜ëœ ëŒ“ê¸€ ìˆ˜: {len(hate_comments)}ê°œ")

                for hc in hate_comments:
                    st.write(f"- {hc}")

            except Exception as e:
                st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")
