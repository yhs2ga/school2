import streamlit as st
import requests
import re
import pickle
from sklearn.metrics.pairwise import cosine_similarity

# Load model
@st.cache_resource
def load_model():
    with open("hate_model.pkl", "rb") as f:
        model = pickle.load(f)
    return model['vectorizer'], model['hate_vectors'], model['hate_texts']

vectorizer, hate_vectors, hate_texts = load_model()

# YouTube API Key
API_KEY = 'AIzaSyCEPm16vLDOuCxBH7eXB8_c8Kk78kfKfJQ'

# Extract video ID (ì§€ì›: watch, youtu.be, embed, shorts ë“±)
def extract_video_id(url):
    match = re.search(
        r"(?:v=|youtu\.be/|embed/|shorts/)([0-9A-Za-z_-]{11})(?:[&?\\s]|$)",
        url
    )
    return match.group(1) if match else None

# Get YouTube comments
def get_comments(video_id):
    comments = []
    next_page_token = None

    while True:
        base_url = (
            f"https://www.googleapis.com/youtube/v3/commentThreads"
            f"?part=snippet&videoId={video_id}&key={API_KEY}&maxResults=100"
        )
        if next_page_token:
            base_url += f"&pageToken={next_page_token}"

        res = requests.get(base_url)
        if res.status_code != 200:
            break

        data = res.json()

        for item in data.get("items", []):
            text = item['snippet']['topLevelComment']['snippet']['textDisplay']
            comments.append(text)

        next_page_token = data.get("nextPageToken")
        if not next_page_token:
            break

    return comments

# ìœ ì‚¬ë„ ê¸°ë°˜ ì•…í”Œ íŒë‹¨
SIMILARITY_THRESHOLD = 0.75

def is_hate(comment):
    vec = vectorizer.transform([comment])
    sims = cosine_similarity(vec, hate_vectors)
    max_sim = sims.max()
    return max_sim >= SIMILARITY_THRESHOLD, max_sim

# Streamlit UI
st.title("ğŸ”¥ ìœ íŠœë¸Œ ì•…í”Œ í•„í„°ë§ê¸° (ìœ ì‚¬ë„ ê¸°ë°˜)")
url = st.text_input("YouTube ì˜ìƒ URL ì…ë ¥")

if st.button("ì•…í”Œ ë¶„ì„ ì‹œì‘"):
    with st.spinner("ëŒ“ê¸€ ìˆ˜ì§‘ ë° ë¶„ì„ ì¤‘..."):
        vid = extract_video_id(url)
        if not vid:
            st.error("ìœ íš¨í•œ YouTube ë§í¬ê°€ ì•„ë‹˜.")
        else:
            try:
                comments = get_comments(vid)
                st.write(f"ì´ ëŒ“ê¸€ ìˆ˜: {len(comments)}ê°œ")
                results = []
                for c in comments:
                    try:
                        is_h, sim = is_hate(c)
                        if is_h:
                            results.append({"ëŒ“ê¸€": c, "ìœ ì‚¬ë„": round(sim, 3)})
                    except:
                        continue
                if results:
                    st.success(f"ì•…í”Œ ê°ì§€ë¨: {len(results)}ê°œ")
                    st.dataframe(results)
                else:
                    st.info("ì•…í”Œ ì—†ìŒ ğŸ‘Œ")
            except Exception as e:
                st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")
