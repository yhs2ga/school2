import streamlit as st
import re
import pickle
from googleapiclient.discovery import build
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from Korpora import Korpora
import os

# -------------------- ìœ íŠœë¸Œ API í‚¤ --------------------
API_KEY = 'AIzaSyCEPm16vLDOuCxBH7eXB8_c8Kk78kfKfJQ'

# -------------------- ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸° --------------------
def get_comments(video_id, api_key, max_results=100):
    youtube = build("youtube", "v3", developerKey=api_key)
    comments = []

    response = youtube.commentThreads().list(
        part="snippet",
        videoId=video_id,
        maxResults=min(max_results, 100),
        textFormat="plainText"
    ).execute()

    for item in response["items"]:
        comment = item["snippet"]["topLevelComment"]["snippet"]["textDisplay"]
        comments.append(comment)

    return comments

# -------------------- ìœ íŠœë¸Œ URLì—ì„œ ID ì¶”ì¶œ --------------------
def extract_video_id(url):
    match = re.search(r"(?:v=|\/)([0-9A-Za-z_-]{11})(?:[&?\\s]|$)", url)
    return match.group(1) if match else None

# -------------------- ëª¨ë¸ í•™ìŠµ ë˜ëŠ” ë¶ˆëŸ¬ì˜¤ê¸° --------------------
def load_or_train_model():
    model_path = "hate_model.pkl"
    vec_path = "vectorizer.pkl"

    if os.path.exists(model_path) and os.path.exists(vec_path):
        with open(model_path, "rb") as f:
            model = pickle.load(f)
        with open(vec_path, "rb") as f:
            vectorizer = pickle.load(f)
    else:
        st.info("ì²˜ìŒ ì‹¤í–‰ ì¤‘... ëª¨ë¸ í•™ìŠµ ì¤‘ì…ë‹ˆë‹¤. 1~2ë¶„ ê±¸ë¦´ ìˆ˜ ìˆìŒ")

        corpus = Korpora.load("korean_hate_speech")

        # ğŸ”§ êµ¬ì¡° ìë™ íŒë³„
        try:
            texts = [sample.text for sample in corpus.train]
            labels = [1 if sample.label in ['hate', 'offensive'] else 0 for sample in corpus.train]
        except AttributeError:
            texts = [text for text, label in corpus.train]
            labels = [1 if label in ['hate', 'offensive'] else 0 for text, label in corpus.train]

        vectorizer = TfidfVectorizer()
        X = vectorizer.fit_transform(texts)
        X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)

        model = LogisticRegression()
        model.fit(X_train, y_train)

        with open(model_path, "wb") as f:
            pickle.dump(model, f)
        with open(vec_path, "wb") as f:
            pickle.dump(vectorizer, f)

    return model, vectorizer

# -------------------- ì•…í”Œ ì˜ˆì¸¡ --------------------
def predict_hate(comments, model, vectorizer):
    X = vectorizer.transform(comments)
    preds = model.predict(X)
    hate_comments = [c for c, p in zip(comments, preds) if p == 1]
    return hate_comments

# -------------------- Streamlit UI --------------------
st.set_page_config(page_title="ìœ íŠœë¸Œ ì•…í”Œ í•„í„°ê¸°", layout="centered")
st.title("ğŸ˜¡ ìœ íŠœë¸Œ ì•…í”Œ í•„í„°ê¸°")
st.caption("ìœ íŠœë¸Œ ì˜ìƒ ëŒ“ê¸€ ì¤‘ ì•…ì„± ëŒ“ê¸€ë§Œ ê³¨ë¼ëƒ…ë‹ˆë‹¤")

url = st.text_input("ìœ íŠœë¸Œ ì˜ìƒ URLì„ ì…ë ¥í•˜ì„¸ìš”:")

if st.button("ë¶„ì„í•˜ê¸°"):
    if not API_KEY or "ì—¬ê¸°ì—" in API_KEY:
        st.error("ìœ íŠœë¸Œ API í‚¤ë¥¼ ë¨¼ì € ì„¤ì •í•´ë¼ ì´ë†ˆì•„.")
    elif not url:
        st.warning("URL ì•ˆ ë„£ê³  ë²„íŠ¼ ëˆ„ë¥´ë©´ ì–´ì©ŒìëŠ” ê±°ëƒ?")
    else:
        with st.spinner("ëŒ“ê¸€ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            video_id = extract_video_id(url)
            if not video_id:
                st.error("ì˜ìƒ ID ì¶”ì¶œ ì‹¤íŒ¨. URL ì œëŒ€ë¡œ ë„£ì—ˆëƒ?")
            else:
                try:
                    comments = get_comments(video_id, API_KEY, max_results=100)
                except Exception as e:
                    st.error(f"ëŒ“ê¸€ ê°€ì ¸ì˜¤ë‹¤ ì—ëŸ¬ë‚¨: {e}")
                    comments = []

        if comments:
            with st.spinner("ì•…í”Œ ë¶„ì„ ì¤‘..."):
                model, vectorizer = load_or_train_model()
                hate_comments = predict_hate(comments, model, vectorizer)

            st.success(f"ì•…í”Œ {len(hate_comments)}ê°œ ë°œê²¬ë¨")
            if hate_comments:
                for i, hc in enumerate(hate_comments, 1):
                    st.write(f"**{i}.** {hc}")
            else:
                st.info("ì•…í”Œ ì—†ìŒ. ì„¸ìƒ ì•„ì§ ì‚´ ë§Œí•˜ë„¤")
